name: Weekly Data Updates

on:
  schedule:
    # Mondays at 7 AM Brazil time (UTC-3) = 10 AM UTC
    - cron: '0 10 * * 1'
  workflow_dispatch:
    inputs:
      target_group:
        description: 'Target group to update'
        required: false
        default: 'weekly'
        type: choice
        options:
          - weekly
          - monthly
          - all

jobs:
  update-weekly-data:
    runs-on: ubuntu-latest
    env:
      GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup R
        uses: r-lib/actions/setup-r@v2
        with:
          r-version: 'release'
          use-public-rspm: true

      - name: Setup R dependencies
        uses: r-lib/actions/setup-r-dependencies@v2
        with:
          extra-packages: |
            any::targets
            any::tarchetypes
            any::cli
            any::here
            any::readr
            any::dplyr
            any::purrr
            any::remotes

      - name: Install package
        run: |
          Rscript -e 'remotes::install_local(".", dependencies = TRUE)'

      - name: Create required directories
        run: |
          mkdir -p data-raw/cache_output
          mkdir -p inst/reports
          mkdir -p _targets

      - name: Check current cache status
        run: |
          Rscript -e 'source("data-raw/pipeline/generate_report.R"); generate_quick_status()'

      - name: Determine targets to run
        id: determine-targets
        run: |
          target_group="${{ github.event.inputs.target_group || 'weekly' }}"

          if [ "$target_group" == "weekly" ]; then
            # Weekly: fetch, cache, validate for high-priority datasets
            targets="bcb_series_data,bcb_series_cache,bcb_series_validation,bcb_realestate_data,bcb_realestate_cache,bcb_realestate_validation,fgv_ibre_data,fgv_ibre_cache,fgv_ibre_validation,abecip_data,abecip_cache,abecip_validation,abrainc_data,abrainc_cache,abrainc_validation,secovi_data,secovi_cache,secovi_validation,rppi_sale_data,rppi_sale_cache,rppi_sale_validation,rppi_rent_data,rppi_rent_cache,rppi_rent_validation,pipeline_summary"
          elif [ "$target_group" == "monthly" ]; then
            # Monthly: fetch, cache, validate for lower-priority datasets
            targets="bis_rppi_data,bis_rppi_cache,bis_rppi_validation,cbic_data,cbic_cache,cbic_validation,property_records_data,property_records_cache,property_records_validation,pipeline_summary"
          elif [ "$target_group" == "all" ]; then
            # All targets (weekly + monthly)
            targets="bcb_series_data,bcb_series_cache,bcb_series_validation,bcb_realestate_data,bcb_realestate_cache,bcb_realestate_validation,fgv_ibre_data,fgv_ibre_cache,fgv_ibre_validation,abecip_data,abecip_cache,abecip_validation,abrainc_data,abrainc_cache,abrainc_validation,secovi_data,secovi_cache,secovi_validation,rppi_sale_data,rppi_sale_cache,rppi_sale_validation,rppi_rent_data,rppi_rent_cache,rppi_rent_validation,bis_rppi_data,bis_rppi_cache,bis_rppi_validation,cbic_data,cbic_cache,cbic_validation,property_records_data,property_records_cache,property_records_validation,pipeline_summary"
          fi

          echo "targets=$targets" >> $GITHUB_OUTPUT
          echo "group=$target_group" >> $GITHUB_OUTPUT

      - name: Run selected targets pipeline
        run: |
          Rscript -e '
            library(targets)

            target_list <- unlist(strsplit("${{ steps.determine-targets.outputs.targets }}", ","))
            target_group <- "${{ steps.determine-targets.outputs.group }}"

            cli::cli_h1("Running {target_group} data pipeline")
            cli::cli_inform("Targets: {paste(target_list, collapse=\", \")}")

            # Run targets with extended timeout for slower sources
            options(timeout = 600)  # 10 minutes per target

            tar_make(names = all_of(target_list))

            cli::cli_alert_success("{target_group} pipeline completed")
          '

      - name: Validate updated data
        run: |
          Rscript -e '
            source("data-raw/pipeline/validation.R")
            source("data-raw/pipeline/targets_helpers.R")

            # Validate cache integrity
            cache_valid <- validate_cache_integrity()

            if (!cache_valid) {
              cli::cli_alert_danger("Cache validation failed!")
              quit(status = 1)
            }

            # Get cache summary for validation
            cache_summary <- get_cache_summary()
            cli::cli_inform("Cache summary:")
            print(cache_summary)

            cli::cli_alert_success("Cache validation passed")
          '

      - name: Generate comprehensive report
        run: |
          Rscript -e 'source("data-raw/pipeline/generate_report.R"); generate_pipeline_report()'

      - name: Create or update cache-latest release
        run: |
          # Check if release exists
          if gh release view cache-latest > /dev/null 2>&1; then
            echo "Release 'cache-latest' already exists"
          else
            echo "Creating release 'cache-latest'"
            gh release create cache-latest \
              --title "Latest Cached Data" \
              --notes "Automatically updated cached datasets. This release is continuously updated by the data pipeline." \
              --prerelease
          fi

      - name: Upload cached datasets to GitHub release
        run: |
          target_group="${{ steps.determine-targets.outputs.group }}"

          # Upload all files from cache_output to the release
          if [ -d "data-raw/cache_output" ] && [ "$(ls -A data-raw/cache_output)" ]; then
            echo "Uploading cached datasets to release 'cache-latest'"

            # Upload files, overwriting existing ones
            for file in data-raw/cache_output/*; do
              if [ -f "$file" ]; then
                filename=$(basename "$file")
                echo "Uploading $filename..."
                gh release upload cache-latest "$file" --clobber
              fi
            done

            echo "Upload completed successfully"
          else
            echo "No cached data files to upload"
          fi

      - name: Commit and push reports
        run: |
          # Only commit reports and targets metadata, not data files
          if [ -n "$(git status --porcelain inst/reports/)" ]; then
            git config --local user.email "actions@github.com"
            git config --local user.name "GitHub Actions"

            git add inst/reports/

            target_group="${{ steps.determine-targets.outputs.group }}"
            git commit -m "chore: update data pipeline reports ($target_group) - $(date +'%Y-%m-%d')"
            git push
          else
            echo "No report changes to commit"
          fi

      - name: Report completion status
        if: always()
        run: |
          target_group="${{ steps.determine-targets.outputs.group }}"
          if [ "${{ job.status }}" == "success" ]; then
            echo "✅ $target_group update completed successfully"
          else
            echo "❌ $target_group update failed"
            exit 1
          fi